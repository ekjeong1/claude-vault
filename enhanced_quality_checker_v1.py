#!/usr/bin/env python3
"""
Enhanced Quality Checker for Obsidian RSI
í™•ì¥ëœ Invariants ê¸°ë°˜ í’ˆì§ˆ ê²€ì¦
"""

import re
from pathlib import Path
from typing import List, Dict, Tuple

class QualityChecker:
    """
    ë…¸íŠ¸ í’ˆì§ˆ ê²€ì¦ í´ë˜ìŠ¤
    """
    
    def __init__(self, invariants_path=None):
        self.issues = []
        self.meta_files_prefixes = ['0_', '1_', '2_', '_']
    
    # ===== Part 1: êµ¬ì¡°ì  í’ˆì§ˆ (ê¸°ì¡´) =====
    
    def check_file_naming(self, file_path: Path) -> List[Dict]:
        """
        íŒŒì¼ ëª…ëª… ê·œì¹™ ê²€ì¦
        """
        issues = []
        name = file_path.stem
        
        # Untitled ì²´í¬
        if 'Untitled' in name:
            issues.append({
                'priority': 'P2',
                'category': 'íŒŒì¼ëª…',
                'file': file_path.name,
                'issue': f"Untitled íŒŒì¼: {name}",
                'suggestion': "ì˜ë¯¸ìˆëŠ” ì´ë¦„ìœ¼ë¡œ ë³€ê²½ í•„ìš”"
            })
        
        return issues
    
    def check_links(self, content: str, file_path: Path) -> List[Dict]:
        """
        ë§í¬ êµ¬ì¡° ê²€ì¦
        """
        issues = []
        
        # ë©”íƒ€ íŒŒì¼ ì œì™¸
        if any(file_path.name.startswith(prefix) for prefix in self.meta_files_prefixes):
            return issues
        
        # ë§í¬ ì¶”ì¶œ [[ë§í¬]]
        links = re.findall(r'\[\[(.*?)\]\]', content)
        
        if len(links) == 0:
            issues.append({
                'priority': 'P2',
                'category': 'ë§í¬',
                'file': file_path.name,
                'issue': "ê³ ì•„ ë…¸íŠ¸ (ë§í¬ ì—†ìŒ)",
                'suggestion': "ìµœì†Œ 1ê°œ ì´ìƒì˜ ê´€ë ¨ ê°œë… ë§í¬ ì¶”ê°€"
            })
        elif len(links) < 2:
            issues.append({
                'priority': 'P3',
                'category': 'ì—°ê²°ì„±',
                'file': file_path.name,
                'issue': "ë§í¬ê°€ 1ê°œë¿ (ê²©ë¦¬ ìœ„í—˜)",
                'suggestion': "2ê°œ ì´ìƒì˜ ê´€ë ¨ ê°œë… ì—°ê²° ê¶Œì¥"
            })
        
        return issues
    
    def check_sections(self, content: str, file_path: Path) -> List[Dict]:
        """
        ì„¹ì…˜ êµ¬ì¡° ê²€ì¦
        """
        issues = []
        
        # ì„¹ì…˜ ì¶”ì¶œ
        sections = re.findall(r'^##\s+(.+)$', content, re.MULTILINE)
        
        # í•µì‹¬ ë‚´ìš© ì„¹ì…˜ ì²´í¬
        core_content_section = None
        for match in re.finditer(r'^##\s+í•µì‹¬\s*ë‚´ìš©\s*$(.*?)(?=^##|\Z)', content, re.MULTILINE | re.DOTALL):
            core_content_section = match.group(1).strip()
            break
        
        if core_content_section is not None:
            if len(core_content_section) < 10:
                issues.append({
                    'priority': 'P1',
                    'category': 'ë¹ˆ ì„¹ì…˜',
                    'file': file_path.name,
                    'issue': "'í•µì‹¬ ë‚´ìš©' ì„¹ì…˜ì´ ë¹„ì–´ìˆìŒ",
                    'suggestion': "í•µì‹¬ ë‚´ìš© ì‘ì„± í•„ìš”"
                })
        
        return issues
    
    # ===== Part 2: ë‚´ìš©ì  í’ˆì§ˆ (ì‹ ê·œ) =====
    
    def check_content_quality(self, content: str, file_path: Path) -> List[Dict]:
        """
        ë‚´ìš© ì¶©ì‹¤ì„± ê²€ì¦
        """
        issues = []
        
        # í•µì‹¬ ë‚´ìš© ê¸¸ì´ ì²´í¬
        core_content_section = None
        for match in re.finditer(r'^##\s+í•µì‹¬\s*ë‚´ìš©\s*$(.*?)(?=^##|\Z)', content, re.MULTILINE | re.DOTALL):
            core_content_section = match.group(1).strip()
            break
        
        if core_content_section:
            if len(core_content_section) < 150:
                issues.append({
                    'priority': 'P2',
                    'category': 'ë‚´ìš© í’ˆì§ˆ',
                    'file': file_path.name,
                    'issue': f"í•µì‹¬ ë‚´ìš©ì´ ì§§ìŒ ({len(core_content_section)}ì)",
                    'suggestion': "ìµœì†Œ 150ì ì´ìƒ ì‘ì„± ê¶Œì¥"
                })
            
            # ëª¨í˜¸í•œ í‘œí˜„ ì²´í¬
            vague_terms = ['ë“±ë“±', 'ë“±ê³¼ ê°™ì€', 'ì—¬ëŸ¬', 'ë‹¤ì–‘í•œ']
            found_vague = [term for term in vague_terms if term in core_content_section]
            if found_vague:
                issues.append({
                    'priority': 'P3',
                    'category': 'ëª…í™•ì„±',
                    'file': file_path.name,
                    'issue': f"ëª¨í˜¸í•œ í‘œí˜„ ë°œê²¬: {', '.join(found_vague)}",
                    'suggestion': "êµ¬ì²´ì ì¸ í‘œí˜„ìœ¼ë¡œ ë³€ê²½ ê¶Œì¥"
                })
        
        return issues
    
    def check_clarity(self, content: str, file_path: Path) -> List[Dict]:
        """
        ì„¤ëª… ëª…í™•ì„± ê²€ì¦
        """
        issues = []
        
        # ë¬¸ì¥ ê¸¸ì´ ì²´í¬
        sentences = re.split(r'[.!?]\s+', content)
        long_sentences = [s for s in sentences if len(s) > 100]
        
        if len(long_sentences) > 5:
            issues.append({
                'priority': 'P3',
                'category': 'ëª…í™•ì„±',
                'file': file_path.name,
                'issue': f"{len(long_sentences)}ê°œ ë¬¸ì¥ì´ ë„ˆë¬´ ê¹€ (100ì ì´ìƒ)",
                'suggestion': "ê¸´ ë¬¸ì¥ì„ ì§§ê²Œ ë¶„ë¦¬ ê¶Œì¥"
            })
        
        return issues
    
    def check_connectivity(self, content: str, file_path: Path) -> List[Dict]:
        """
        ê°œë… ì—°ê²°ì„± ê²€ì¦
        """
        issues = []
        
        # ë©”íƒ€ íŒŒì¼ ì œì™¸
        if any(file_path.name.startswith(prefix) for prefix in self.meta_files_prefixes):
            return issues
        
        # ë§í¬ì™€ ë§¥ë½ ì²´í¬
        links = re.findall(r'\[\[(.*?)\]\]', content)
        
        # ë§¥ë½ ìˆëŠ” ë§í¬ (ë§í¬ ì£¼ë³€ì— ì„¤ëª…ì´ ìˆëŠ”ì§€)
        contextual_links = 0
        for match in re.finditer(r'(.{20})\[\[.*?\]\](.{20})', content):
            before = match.group(1).strip()
            after = match.group(2).strip()
            # ì•ë’¤ì— í•œê¸€ì´ ìˆìœ¼ë©´ ë§¥ë½ ìˆëŠ” ë§í¬ë¡œ íŒë‹¨
            if (any('\uac00' <= c <= '\ud7a3' for c in before) or 
                any('\uac00' <= c <= '\ud7a3' for c in after)):
                contextual_links += 1
        
        if links and contextual_links / len(links) < 0.3:
            issues.append({
                'priority': 'P3',
                'category': 'ì—°ê²°ì„±',
                'file': file_path.name,
                'issue': f"ë§í¬ ì¤‘ ë§¥ë½ ì—†ëŠ” ê²ƒì´ ë§ìŒ ({contextual_links}/{len(links)})",
                'suggestion': "ë§í¬ì— ì„¤ëª… ì¶”ê°€ ê¶Œì¥"
            })
        
        return issues
    
    def check_rag_optimization(self, content: str, file_path: Path) -> List[Dict]:
        """
        RAG ìµœì í™” ê²€ì¦ (Phase 5 ê¸°ì¤€)
        """
        issues = []
        
        # ë©”íƒ€ íŒŒì¼ ì œì™¸
        if any(file_path.name.startswith(prefix) for prefix in self.meta_files_prefixes):
            return issues
        
        char_count = len(content)
        sections = re.findall(r'^##\s+', content, re.MULTILINE)
        section_count = len(sections)
        
        # ê¸¸ì´ ì²´í¬
        if char_count < 1000:
            issues.append({
                'priority': 'P2',
                'category': 'RAG ìµœì í™”',
                'file': file_path.name,
                'issue': f"ë…¸íŠ¸ê°€ ì§§ìŒ ({char_count}ì)",
                'suggestion': "1,500-2,000ì ê¶Œì¥ (Phase 5 ê¸°ì¤€)"
            })
        elif char_count > 3500:
            issues.append({
                'priority': 'P2',
                'category': 'RAG ìµœì í™”',
                'file': file_path.name,
                'issue': f"ë…¸íŠ¸ê°€ ë„ˆë¬´ ê¹€ ({char_count}ì)",
                'suggestion': "2,000ì ì´í•˜ ê¶Œì¥ - V3ì˜ ì—­ì„¤ ì°¸ê³ "
            })
        
        # ì„¹ì…˜ ìˆ˜ ì²´í¬
        if section_count > 0:
            if section_count < 4:
                issues.append({
                    'priority': 'P3',
                    'category': 'RAG ìµœì í™”',
                    'file': file_path.name,
                    'issue': f"ì„¹ì…˜ ë¶€ì¡± ({section_count}ê°œ)",
                    'suggestion': "5-8ê°œ ì„¹ì…˜ ê¶Œì¥"
                })
            elif section_count > 10:
                issues.append({
                    'priority': 'P3',
                    'category': 'RAG ìµœì í™”',
                    'file': file_path.name,
                    'issue': f"ì„¹ì…˜ ê³¼ë‹¤ ({section_count}ê°œ)",
                    'suggestion': "5-8ê°œ ì„¹ì…˜ ê¶Œì¥"
                })
            
            # ì •ë³´ ë°€ë„
            density = char_count / section_count
            if density < 150:
                issues.append({
                    'priority': 'P3',
                    'category': 'RAG ìµœì í™”',
                    'file': file_path.name,
                    'issue': f"ì •ë³´ ë°€ë„ ë‚®ìŒ ({density:.0f}ì/ì„¹ì…˜)",
                    'suggestion': "200-250ì/ì„¹ì…˜ ê¶Œì¥"
                })
            elif density > 450:
                issues.append({
                    'priority': 'P3',
                    'category': 'RAG ìµœì í™”',
                    'file': file_path.name,
                    'issue': f"ì •ë³´ ë°€ë„ ë†’ìŒ ({density:.0f}ì/ì„¹ì…˜)",
                    'suggestion': "200-250ì/ì„¹ì…˜ ê¶Œì¥"
                })
        
        return issues
    
    def check_example_quality(self, content: str, file_path: Path) -> List[Dict]:
        """
        ì˜ˆì œ í’ˆì§ˆ ê²€ì¦
        """
        issues = []
        
        # ì˜ˆì œ/ì‚¬ë¡€ ì„¹ì…˜ ì°¾ê¸°
        example_sections = re.findall(
            r'^###\s+(ì‚¬ë¡€|ì˜ˆì œ|Example)\s+\d+:?\s*(.+?)$\n(.*?)(?=^###|^##|\Z)',
            content,
            re.MULTILINE | re.DOTALL
        )
        
        if len(example_sections) > 4:
            issues.append({
                'priority': 'P3',
                'category': 'ì˜ˆì œ í’ˆì§ˆ',
                'file': file_path.name,
                'issue': f"ì˜ˆì œê°€ ë„ˆë¬´ ë§ìŒ ({len(example_sections)}ê°œ)",
                'suggestion': "2-3ê°œ ê¶Œì¥ (Phase 5: V3ì˜ 3ê°œ ê°•ì œ ë¬¸ì œ)"
            })
        
        # ê° ì˜ˆì œ í’ˆì§ˆ ì²´í¬
        vague_terms = ['ì–´ë–¤', 'íŠ¹ì •', 'ì¼ë¶€']
        for i, (label, title, content_part) in enumerate(example_sections, 1):
            # ì¶”ìƒì  í‘œí˜„ ì²´í¬
            if any(term in title or term in content_part for term in vague_terms):
                issues.append({
                    'priority': 'P3',
                    'category': 'ì˜ˆì œ í’ˆì§ˆ',
                    'file': file_path.name,
                    'issue': f"ì˜ˆì œ {i}ê°€ ì¶”ìƒì ",
                    'suggestion': "êµ¬ì²´ì ì¸ ì´ë¦„/ìˆ«ì í¬í•¨ ê¶Œì¥"
                })
            
            # ê¸¸ì´ ì²´í¬
            if len(content_part.strip()) < 100:
                issues.append({
                    'priority': 'P3',
                    'category': 'ì˜ˆì œ í’ˆì§ˆ',
                    'file': file_path.name,
                    'issue': f"ì˜ˆì œ {i} ì„¤ëª…ì´ ì§§ìŒ ({len(content_part)}ì)",
                    'suggestion': "ìµœì†Œ 100ì ì´ìƒ ê¶Œì¥"
                })
        
        return issues
    
    def calculate_quality_score(self, all_issues: List[Dict]) -> int:
        """
        í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0-100)
        """
        score = 100
        
        for issue in all_issues:
            if issue['priority'] == 'P1':
                score -= 15
            elif issue['priority'] == 'P2':
                score -= 5
            elif issue['priority'] == 'P3':
                score -= 2
        
        return max(0, score)
    
    def check_note(self, file_path: Path) -> Tuple[int, List[Dict]]:
        """
        ë‹¨ì¼ ë…¸íŠ¸ ê²€ì¦
        """
        if not file_path.exists():
            return 0, []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        all_issues = []
        
        # Part 1: êµ¬ì¡°ì  í’ˆì§ˆ
        all_issues.extend(self.check_file_naming(file_path))
        all_issues.extend(self.check_links(content, file_path))
        all_issues.extend(self.check_sections(content, file_path))
        
        # Part 2: ë‚´ìš©ì  í’ˆì§ˆ
        all_issues.extend(self.check_content_quality(content, file_path))
        all_issues.extend(self.check_clarity(content, file_path))
        all_issues.extend(self.check_connectivity(content, file_path))
        all_issues.extend(self.check_rag_optimization(content, file_path))
        all_issues.extend(self.check_example_quality(content, file_path))
        
        # ì ìˆ˜ ê³„ì‚°
        score = self.calculate_quality_score(all_issues)
        
        return score, all_issues


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    print("="*60)
    print("Enhanced Quality Checker for Obsidian RSI")
    print("="*60)
    
    # Vault ê²½ë¡œ ì„¤ì • (ìˆ˜ì • í•„ìš”)
    vault_path = Path("C:\Users\win10_original\claude-vault")
    
    if not vault_path.exists():
        print(f"âŒ Error: Vault not found at {vault_path}")
        return
    
    print(f"\nğŸ“‚ Vault: {vault_path}")
    
    # ëª¨ë“  .md íŒŒì¼ ì°¾ê¸°
    md_files = list(vault_path.glob("**/*.md"))
    print(f"ğŸ“„ Found {len(md_files)} markdown files")
    
    # í’ˆì§ˆ ì²´ì»¤ ì´ˆê¸°í™”
    checker = QualityChecker()
    
    # ì „ì²´ í†µê³„
    all_issues = []
    scores = {}
    
    print("\nğŸ” Checking notes...")
    
    for file_path in md_files:
        score, issues = checker.check_note(file_path)
        
        if issues:
            all_issues.extend(issues)
            scores[file_path.name] = score
    
    print(f"âœ“ Checked {len(md_files)} files")
    print(f"âœ“ Found {len(all_issues)} issues")
    
    # í†µê³„ ì¶œë ¥
    print("\n" + "="*60)
    print("ğŸ“Š Quality Statistics")
    print("="*60)
    
    if scores:
        avg_score = sum(scores.values()) / len(scores)
        print(f"\ní‰ê·  í’ˆì§ˆ ì ìˆ˜: {avg_score:.1f}/100")
        
        # ë“±ê¸‰ë³„ ë¶„í¬
        excellent = sum(1 for s in scores.values() if s >= 90)
        good = sum(1 for s in scores.values() if 75 <= s < 90)
        fair = sum(1 for s in scores.values() if 60 <= s < 75)
        poor = sum(1 for s in scores.values() if s < 60)
        
        print(f"\në“±ê¸‰ ë¶„í¬:")
        print(f"  Excellent (90-100): {excellent}ê°œ")
        print(f"  Good (75-89): {good}ê°œ")
        print(f"  Fair (60-74): {fair}ê°œ")
        print(f"  Poor (0-59): {poor}ê°œ")
    
    # ìš°ì„ ìˆœìœ„ë³„ í†µê³„
    if all_issues:
        print(f"\nìš°ì„ ìˆœìœ„ë³„ ì´ìŠˆ:")
        p1_count = sum(1 for i in all_issues if i['priority'] == 'P1')
        p2_count = sum(1 for i in all_issues if i['priority'] == 'P2')
        p3_count = sum(1 for i in all_issues if i['priority'] == 'P3')
        
        print(f"  P1 (Critical): {p1_count}ê°œ")
        print(f"  P2 (Important): {p2_count}ê°œ")
        print(f"  P3 (Nice-to-have): {p3_count}ê°œ")
        
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        from collections import Counter
        categories = Counter(i['category'] for i in all_issues)
        
        print(f"\nì¹´í…Œê³ ë¦¬ë³„ ì´ìŠˆ (Top 5):")
        for category, count in categories.most_common(5):
            print(f"  {category}: {count}ê°œ")
    
    # ë‚®ì€ ì ìˆ˜ íŒŒì¼ ì¶œë ¥
    if scores:
        print(f"\nâš ï¸ ê°œì„  í•„ìš” íŒŒì¼ (ì ìˆ˜ < 70):")
        low_scores = [(name, score) for name, score in scores.items() if score < 70]
        low_scores.sort(key=lambda x: x[1])
        
        for name, score in low_scores[:10]:
            print(f"  {name}: {score:.0f}ì ")
    
    print("\n" + "="*60)
    print("âœ¨ Quality check completed!")
    print("="*60)


if __name__ == "__main__":
    main()
